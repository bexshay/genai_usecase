{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7832d2",
   "metadata": {},
   "source": [
    "[Source: Basic_Rag_Example.ipynb](https://gitlab.k8s.cloud.statcan.ca/bptas/initiatives/llm-the-zone/-/blob/main/Basic_Rag_Example.ipynb?ref_type=heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a75c7",
   "metadata": {},
   "source": [
    "Install required packages:\n",
    "- pip install scikit-learn\n",
    "- pip install azure-identity\n",
    "- pip install PyPDF2\n",
    "- pip install dotenv\n",
    "- pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from google import genai\n",
    "from google.genai import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "os.chdir(\"/home/bex/Documents/git/genai_usecase/\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e014c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the folder path\n",
    "folder_path = \"data/input/\"\n",
    "\n",
    "# 2. Initialize an empty list\n",
    "pdf_files_list = []\n",
    "\n",
    "# 3. Loop through all items in the directory\n",
    "for f in os.listdir(folder_path):\n",
    "    # Check if the item ends with '.pdf' and is a file\n",
    "    # if f.lower().endswith('.pdf') and os.path.isfile(os.path.join(folder_path, f)) and f.startswith('ac') and 'short' not in f:\n",
    "    if f.lower().endswith('.pdf') and os.path.isfile(os.path.join(folder_path, f)) and f.startswith('ac'):\n",
    "        # Append the full path to the list\n",
    "        full_path = os.path.join(folder_path, f)\n",
    "        pdf_files_list.append(full_path)\n",
    "\n",
    "\n",
    "print(f\"Total PDF files found: {len(pdf_files_list)}\")\n",
    "print(\"\\nList of full paths:\")\n",
    "for path in pdf_files_list[:3]: # Print first 3 for brevity\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7073803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdfRagExtractor:\n",
    "    def __init__(self, question, pdf_path):\n",
    "        self.PDF_PATH = pdf_path\n",
    "        self.question = question \n",
    "\n",
    "    def chunk_text(self, max_len=1000, overlap=200):\n",
    "        # Read & extract text from the PDF\n",
    "        PDF_PATH = self.PDF_PATH\n",
    "        reader = PdfReader(PDF_PATH)\n",
    "        pages = [page.extract_text() or \"\" for page in reader.pages]\n",
    "        text = \"\\n\".join(pages)\n",
    "\n",
    "        # Chunk the text into overlapping windows\n",
    "        tokens = text.split()\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(tokens):\n",
    "            end = min(start + max_len, len(tokens))\n",
    "            chunks.append(\" \".join(tokens[start:end]))\n",
    "            if end == len(tokens):\n",
    "                break\n",
    "            start = end - overlap\n",
    "\n",
    "        # Build a TF-IDF retriever over the chunks\n",
    "        vectorizer = TfidfVectorizer().fit(chunks)\n",
    "        chunk_vectors = vectorizer.transform(chunks)\n",
    "        return chunks, vectorizer, chunk_vectors\n",
    "\n",
    "    def retrieve_top_k(self, question, k=5):\n",
    "        chunks, vectorizer, chunk_vectors = self.chunk_text()\n",
    "        q_vec = vectorizer.transform([question])\n",
    "        # Cosine similarity via dot product (TF-IDF is L2-normalized by default)\n",
    "        scores = (chunk_vectors @ q_vec.T).toarray().squeeze()\n",
    "        top_idxs = np.argsort(scores)[-k:][::-1]\n",
    "        return [chunks[i] for i in top_idxs]\n",
    "\n",
    "    # RAG query function using your chat deployment\n",
    "    def rag_query(self, top_k: int = 5) -> str:\n",
    "        question = self.question\n",
    "\n",
    "        snippets = self.retrieve_top_k(question, top_k)\n",
    "\n",
    "        context = \"\\n\\n---\\n\\n\".join(snippets)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "            Based on the following text:\n",
    "            ---\n",
    "            {context}\\n\\n\n",
    "            ---\n",
    "            Provide the answer to the following question in a single numeric value without any words, if not found set answer to NA.\n",
    "            {question}\\n\\n\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Sending a completion job with retrieved contextâ€¦\")\n",
    "        # print(prompt)\n",
    "        client = genai.Client()\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
    "            ),\n",
    "        )\n",
    "        print(response.text)\n",
    "\n",
    "        # # Response from OpenAI\n",
    "        # # print(response.choices[0].message.content)\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a161f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with questions\n",
    "q_dict = {\n",
    "  \"q1\": \"In Pensions and other benefit liabilities, what is the company's fair value of plan assets for the most recent fiscal year for pension benefits plans?\",\n",
    "  \"q2\": \"In Pensions and other benefit liabilities, what is the company's defined benefit obligation as of the end of fiscal year for pension benefits plans?\",\n",
    "  \"q3\": \"In Pensions and other benefit liabilities, what is the value of employer pension contributions for the most recent fiscal year?\",\n",
    "  \"q4\": \"In Pensions and other benefit liabilities, what is the value of employee pension contributions for the most recent fiscal year?\",\n",
    "  \"q5\": \"In Pensions and other benefit liabilities, what is the current service cost for the most recent reporting date?\",\n",
    "  \"q6\": \"What is the current pension administrative expenses for the most recent reporting date?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a403cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to collect results\n",
    "re_dict = {\n",
    "  \"files\": []\n",
    "}\n",
    "\n",
    "# Empty list to collect records\n",
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_file in pdf_files_list[:2]:\n",
    "  # Create a dictionary for the new file (e.g., 2022 data)\n",
    "  file_name = os.path.basename(pdf_file)\n",
    "\n",
    "  print(f\"Processing {file_name}\")\n",
    "\n",
    "  new_file_record = {\n",
    "    file_name: {}\n",
    "  }\n",
    "\n",
    "  for q in q_dict:\n",
    "    # print(q)\n",
    "    RagCall = pdfRagExtractor(question= q_dict[f\"{q}\"], pdf_path=pdf_file)\n",
    "    RagResult = RagCall.rag_query()\n",
    "\n",
    "    # Initialize the nested question dictionary\n",
    "    # You must create the inner dictionary before assigning its keys.\n",
    "    # The variable 'q' (e.g., \"q1\") becomes the new key.\n",
    "    new_file_record[file_name][q] = {}\n",
    "\n",
    "    # Add question and value\n",
    "    new_file_record[file_name][q][\"question\"] = q_dict[f\"{q}\"]\n",
    "    new_file_record[file_name][q][\"value\"] = RagResult\n",
    "\n",
    "    # Create a new dictionary for each row\n",
    "    row = {\n",
    "        'file_name': file_name,\n",
    "        'question_id': q,\n",
    "        'question': q_dict[f\"{q}\"],\n",
    "        'value': RagResult\n",
    "    }\n",
    "\n",
    "    records.append(row)\n",
    "  \n",
    "  # Append the New Record to the 'files' List\n",
    "  re_dict['files'].append(new_file_record)\n",
    "\n",
    "  # print(f\"Finished {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of records to a DataFrame ---\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(\"data/output/output_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump as JSON (optional)\n",
    "import json\n",
    "\n",
    "output_file = 'data/output/report_data.json'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    # Use json.dump(dictionary, file_object)\n",
    "    json.dump(re_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faac400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specific questions\n",
    "RagCall = pdfRagExtractor(question= q_dict[\"q5\"], pdf_path=pdf_files_list[3])\n",
    "RagResult = RagCall.rag_query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
